# Hot/Cold Architecture - Implementation Guide

## âœ… å®Ÿè£…å®Œäº†ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ

### 1. D1 Schema
- **File:** `docs/sql/d1/hot-cold-schema.sql`
- **Tables:** `buffer_logs`, `archived_files`, `block_indexes`
- **Views:** `hot_cold_summary`, `archive_efficiency`

### 2. Buffer Consumer (Queue â†’ D1 Hot Storage)
- **File:** `packages/FUSOU-WORKFLOW/src/buffer-consumer.ts`
- **Features:**
  - Bulk Insertæœ€é©åŒ– (100+ records/query)
  - Chunkedå‡¦ç† (å¤§è¦æ¨¡ãƒãƒƒãƒå¯¾å¿œ)
  - é«˜é€ŸACK (ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ < 500ms)

### 3. Archiver (Cron Worker: Hot â†’ Cold)
- **File:** `packages/FUSOU-WORKFLOW/src/archiver.ts`
- **Features:**
  - Manual Avro Block Construction
  - Byte-level indexing
  - åœ§ç¸®ã‚µãƒãƒ¼ãƒˆ (deflate)
  - å®‰å…¨ãªãƒãƒƒãƒ•ã‚¡ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—

### 4. Compression Utilities
- **File:** `packages/FUSOU-WORKFLOW/src/utils/compression.ts`
- **Codecs:** deflate (snappyå¯¾å¿œæº–å‚™æ¸ˆã¿)
- **API:** async/sync, streamingå¯¾å¿œ

### 5. Reader API (Hot + Cold Merge)
- **File:** `packages/FUSOU-WORKFLOW/src/reader.ts`
- **Features:**
  - R2 Range Requestæœ€é©åŒ–
  - ä¸¦åˆ—ãƒ–ãƒ­ãƒƒã‚¯å–å¾—
  - Hot/Coldãƒãƒ¼ã‚¸ãƒ»é‡è¤‡æ’é™¤
  - ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ˜ãƒƒãƒ€ãƒ¼æœ€é©åŒ–

---

## ğŸš€ ãƒ‡ãƒ—ãƒ­ã‚¤æ‰‹é †

### Step 1: D1ã‚¹ã‚­ãƒ¼ãƒé©ç”¨

```bash
cd packages/FUSOU-WORKFLOW

# Localç’°å¢ƒ
npx wrangler d1 execute dev_kc_battle_index --local \
  --file=../../docs/sql/d1/hot-cold-schema.sql

# Remoteç’°å¢ƒ
npx wrangler d1 execute dev_kc_battle_index --remote \
  --file=../../docs/sql/d1/hot-cold-schema.sql
```

### Step 2: wrangler.tomlè¨­å®š

`packages/FUSOU-WORKFLOW/wrangler.toml`ã«ä»¥ä¸‹ã‚’è¿½åŠ :

```toml
# âœ… Already present: compatibility_flags = ["nodejs_compat"]

# Scheduled Worker (Archiver - æ¯æ™‚å®Ÿè¡Œ)
[triggers]
crons = ["0 * * * *"]  # Every hour at minute 0

# Queue Consumer (Buffer Writer)
[[queues.consumers]]
queue = "dev-kc-buffer-queue"
max_batch_size = 100
max_batch_timeout = 2
max_retries = 3
dead_letter_queue = "dev-kc-buffer-dlq"
```

### Step 3: ãƒ¡ã‚¤ãƒ³Workerã¸ã®çµ±åˆ

`packages/FUSOU-WORKFLOW/src/index.ts`ã«è¿½åŠ :

```typescript
import BufferConsumer from './buffer-consumer';
import Archiver from './archiver';
import Reader from './reader';

export default {
  // æ—¢å­˜ã®fetchãƒãƒ³ãƒ‰ãƒ©
  async fetch(request: Request, env: Env): Promise<Response> {
    const url = new URL(request.url);
    
    // Reader API
    if (url.pathname.startsWith('/v1/read')) {
      return await Reader.fetch(request, env);
    }
    
    // æ—¢å­˜ã®ãƒãƒ³ãƒ‰ãƒ©...
    return new Response('Not Found', { status: 404 });
  },
  
  // Queue Consumer (Buffer Writer)
  async queue(batch: MessageBatch, env: Env): Promise<void> {
    await BufferConsumer.queue(batch, env);
  },
  
  // Scheduled Worker (Archiver)
  async scheduled(event: ScheduledEvent, env: Env, ctx: ExecutionContext): Promise<void> {
    await Archiver.scheduled(event, env, ctx);
  }
};
```

### Step 4: Queueä½œæˆ

```bash
# Buffer Queue
npx wrangler queues create dev-kc-buffer-queue

# Dead Letter Queue
npx wrangler queues create dev-kc-buffer-dlq
```

### Step 5: ãƒ‡ãƒ—ãƒ­ã‚¤

```bash
cd packages/FUSOU-WORKFLOW
npx wrangler deploy
```

---

## ğŸ§ª ãƒ†ã‚¹ãƒˆ

### 1. Buffer Writer ãƒ†ã‚¹ãƒˆ (Hot Storage)

```bash
# Ingest APIã«ãƒ‡ãƒ¼ã‚¿é€ä¿¡
curl -X POST http://localhost:8787/v1/ingest \
  -H "Content-Type: application/json" \
  -d '{
    "dataset_id": "test-user-001",
    "table": "battle",
    "records": [
      {"timestamp": 1703001600000, "api_no": 1, "data": "test1"},
      {"timestamp": 1703001660000, "api_no": 2, "data": "test2"}
    ]
  }'

# D1ã§ãƒãƒƒãƒ•ã‚¡ç¢ºèª
npx wrangler d1 execute dev_kc_battle_index --local \
  --command="SELECT COUNT(*) FROM buffer_logs"
```

### 2. Archiver ãƒ†ã‚¹ãƒˆ (Hot â†’ Cold)

```bash
# æ‰‹å‹•ãƒˆãƒªã‚¬ãƒ¼ (Cronå¾…ãŸãšã«ãƒ†ã‚¹ãƒˆ)
npx wrangler dev
# Then visit: http://localhost:8787/__scheduled?cron=0+*+*+*+*

# R2ã§ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ç¢ºèª
npx wrangler r2 object list dev-kc-battle-data --prefix="battle/"

# D1ã§ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç¢ºèª
npx wrangler d1 execute dev_kc_battle_index --local \
  --command="SELECT * FROM block_indexes LIMIT 5"
```

### 3. Reader API ãƒ†ã‚¹ãƒˆ (Hot + Cold Merge)

```bash
# Hot + Coldãƒ‡ãƒ¼ã‚¿å–å¾—
curl "http://localhost:8787/v1/read?dataset_id=test-user-001&table_name=battle&from=1703001600000&to=1703005200000"

# ãƒ¬ã‚¹ãƒãƒ³ã‚¹ä¾‹:
# {
#   "dataset_id": "test-user-001",
#   "table_name": "battle",
#   "record_count": 42,
#   "hot_count": 10,
#   "cold_count": 32,
#   "records": [...]
# }
```

---

## ğŸ“Š ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°

### Hot/Coldåˆ†å¸ƒç¢ºèª

```sql
SELECT * FROM hot_cold_summary;
```

### åœ§ç¸®åŠ¹ç‡ç¢ºèª

```sql
SELECT * FROM archive_efficiency ORDER BY compression_ratio DESC;
```

### å¤ã„Hotãƒ‡ãƒ¼ã‚¿æ¤œå‡º (2æ™‚é–“ä»¥ä¸Š)

```sql
SELECT COUNT(*) FROM buffer_logs 
WHERE created_at < (strftime('%s', 'now') * 1000) - (2 * 60 * 60 * 1000);
```

---

## âš ï¸ æ³¨æ„äº‹é …

### 1. æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨ã®å…±å­˜

- **ç¾åœ¨ã®`avro_files`/`avro_segments`ãƒ†ãƒ¼ãƒ–ãƒ«ã¯å‰Šé™¤ã—ãªã„**
- Hot/Coldã‚·ã‚¹ãƒ†ãƒ ã¯**ä¸¦è¡Œé‹ç”¨**
- æ®µéšçš„ç§»è¡Œ: æ–°è¦ãƒ‡ãƒ¼ã‚¿ â†’ Hot/Coldã€æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ â†’ å¾“æ¥ã‚·ã‚¹ãƒ†ãƒ 

### 2. ã‚³ã‚¹ãƒˆæœ€é©åŒ–

- **D1 Writes:** Bulk Insertå¿…é ˆ (1ä»¶ãšã¤ç¦æ­¢)
- **R2 Reads:** Range Requestå¿…é ˆ (å…¨ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç¦æ­¢)
- **åœ§ç¸®:** deflateæ¨å¥¨ (2-5xå‰Šæ¸›)

### 3. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›®æ¨™

| æ“ä½œ | ç›®æ¨™ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· |
|------|---------------|
| Hot Read (D1) | < 50ms |
| Cold Read (1 block) | < 200ms |
| Cold Read (multi-block) | < 500ms |
| Archival (hourly) | < 5 minutes |

---

## ğŸ”„ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

### Phase 1 (å®Œäº† âœ…)
- [x] D1ã‚¹ã‚­ãƒ¼ãƒè¨­è¨ˆ
- [x] Buffer Consumerå®Ÿè£…
- [x] Archiverå®Ÿè£…
- [x] Reader APIå®Ÿè£…
- [x] åœ§ç¸®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£

### Phase 2 (æœªå®Ÿè£…)
- [ ] æ—¢å­˜`avro_files`ã¨ã®çµ±åˆ
- [ ] Durable Object Cache for Block Index
- [ ] Snappyåœ§ç¸®ã‚µãƒãƒ¼ãƒˆ
- [ ] Analytics Dashboard

### Phase 3 (æœ€é©åŒ–)
- [ ] Auto-scaling Archiver (è² è·ã«å¿œã˜ã¦é »åº¦èª¿æ•´)
- [ ] Multi-region R2 Replication
- [ ] Advanced Caching Strategy

---

## ğŸ“– å‚è€ƒè³‡æ–™

- [Architecture Design](../ARCHITECTURE_HOT_COLD.md)
- [D1 Schema](../docs/sql/d1/hot-cold-schema.sql)
- [Avro Manual Construction](./src/avro-manual.ts)
- [Compression Utilities](./src/utils/compression.ts)

---

**Status:** Implementation Complete âœ…  
**Ready for:** Testing & Deployment  
**Estimated Cost Reduction:** 60-80% (vs. direct R2 full-file access)
