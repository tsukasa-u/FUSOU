# ãƒ‡ãƒ—ãƒ­ã‚¤å¾Œã®è¨­å®šç¢ºèªãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

## ğŸ”§ Cloudflare Pages (FUSOU-WEB)

### ç’°å¢ƒå¤‰æ•°è¨­å®š
- [ ] **DOTENV_PRIVATE_KEY**
  - `packages/FUSOU-WEB/.env.production.keys` ã‹ã‚‰å€¤ã‚’ã‚³ãƒ”ãƒ¼
  - Dashboard â†’ Settings â†’ Environment Variables â†’ Production
  - ã‚­ãƒ¼: `DOTENV_PRIVATE_KEY`
  - å€¤: `.env.production.keys` ã® DOTENV_PRIVATE_KEY ã®å€¤

- [ ] **PUBLIC_SUPABASE_URL**
  - å€¤: `https://your-project.supabase.co`
  - ã‚¹ã‚³ãƒ¼ãƒ—: Production

- [ ] **SUPABASE_SECRET_KEY**
  - å€¤: Supabase Project Settings â†’ API Keys â†’ Service Role Key
  - ã‚¹ã‚³ãƒ¼ãƒ—: Production

### ã‚µãƒ¼ãƒ“ã‚¹ãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ç¢ºèª
- [ ] **COMPACTION_WORKFLOW** ãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°
  - Dashboard â†’ Settings â†’ Functions â†’ Service bindings
  - Binding: `COMPACTION_WORKFLOW`
  - Service: `fusou-workflow` (åŒã˜ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ)

### R2 ãƒã‚±ãƒƒãƒˆç¢ºèª
- [ ] **ASSETS_BUCKET** â†’ `dev-kc-assets` (å­˜åœ¨ç¢ºèª)
- [ ] **ASSET_SYNC_BUCKET** â†’ `dev-kc-assets` or å°‚ç”¨ãƒã‚±ãƒƒãƒˆ (å­˜åœ¨ç¢ºèª)
- [ ] **FLEET_SNAPSHOT_BUCKET** â†’ `dev-kc-fleets` (å­˜åœ¨ç¢ºèª)
- [ ] **BATTLE_DATA_BUCKET** â†’ `dev-kc-battle-data` (å­˜åœ¨ç¢ºèª)

### D1 ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç¢ºèªï¼ˆæ–°è¦ï¼‰
- [ ] **ASSET_INDEX_DB** â†’ `dev_kc_asset_index` (æ—¢å­˜ã€ã‚¢ã‚»ãƒƒãƒˆç´¢å¼•ç”¨)
- [ ] **BATTLE_INDEX_DB** â†’ `dev_kc_battle_index` (æ–°è¦ã€ãƒãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ç´¢å¼•ç”¨)
  - Cloudflare Dashboard â†’ D1 â†’ ã€ŒCreate databaseã€
  - ä½œæˆå¾Œã€`wrangler.toml` ã® `database_id` ã‚’æ›´æ–°
  - SQLåˆæœŸåŒ–: `wrangler d1 execute <database_id> --file docs/sql/battle_index_init.sql`

### ã‚­ãƒ¥ãƒ¼è¨­å®šç¢ºèª
- [ ] **COMPACTION_QUEUE** ãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°
  - Dashboard â†’ Queues â†’ `dev-kc-compaction-queue` (ä½œæˆæ¸ˆã¿ç¢ºèª)

---

## ğŸ”§ Cloudflare Workers (FUSOU-WORKFLOW)

### ç’°å¢ƒå¤‰æ•°è¨­å®š
- [ ] **DOTENV_PRIVATE_KEY** (Secret)
  ```bash
  wrangler secret put DOTENV_PRIVATE_KEY
  # å€¤: .env.keys ã‹ã‚‰ DOTENV_PRIVATE_KEY ã‚’ãƒšãƒ¼ã‚¹ãƒˆ
  ```

- [ ] **PUBLIC_SUPABASE_URL** (Environment Variable)
  ```toml
  # wrangler.toml ã« [vars] ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§è¨­å®š
  # ã¾ãŸã¯ Dashboard â†’ Settings â†’ Variables
  ```

- [ ] **SUPABASE_SECRET_KEY** (Secret)
  ```bash
  wrangler secret put SUPABASE_SECRET_KEY
  ```

### Workflow å®šç¾©ç¢ºèª
- [ ] **DataCompactionWorkflow** ã‚¯ãƒ©ã‚¹
  - `src/index.ts` ã§ export ã•ã‚Œã¦ã„ã‚‹
  - 4-step workflow ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹

### ã‚­ãƒ¥ãƒ¼ Consumer ç¢ºèª
- [ ] **dev-kc-compaction-queue** Consumer
  - `max_batch_size: 10`
  - `max_batch_timeout: 30`
  - `max_retries: 3`
  - `dead_letter_queue: dev-kc-compaction-dlq`

### ã‚­ãƒ¥ãƒ¼ DLQ Handler ç¢ºèª
- [ ] **dev-kc-compaction-dlq** Consumer
  - `max_batch_size: 5`
  - `max_batch_timeout: 60`
  - `max_retries: 1`

---

## ğŸ“‹ GitHub Actions

### GitHub Secrets è¨­å®š
- [ ] **PAGES_DOMAIN**
  - å€¤: `fusou.pages.dev` (ã¾ãŸã¯æœ¬ç•ªãƒ‰ãƒ¡ã‚¤ãƒ³)
  - Repository Settings â†’ Secrets and variables â†’ Actions

### ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ç¢ºèª
- [ ] **.github/workflows/trigger_daily_compaction.yml**
  - æœ‰åŠ¹åŒ–ç¢ºèª: Actions ã‚¿ãƒ–ã§è¦‹ãˆã‚‹ã‹
  - Cron: `0 2 * * *` (æ¯æ—¥ 02:00 UTC)
  - æ‰‹å‹•ãƒˆãƒªã‚¬ãƒ¼: `workflow_dispatch` ãŒæœ‰åŠ¹

### æ‰‹å‹•ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
- [ ] Actions â†’ "Daily Compaction Trigger" â†’ "Run workflow" ã§ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
  - HTTP Status: 200 or 201 ãŒè¿”ã£ã¦ãã‚‹
  - ãƒ­ã‚°ã« "Enqueued" ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¡¨ç¤ºã•ã‚Œã‚‹

---

## ğŸ“Š Supabase

### ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆç¢ºèª
- [ ] **datasets** ãƒ†ãƒ¼ãƒ–ãƒ«
  - ã‚«ãƒ©ãƒ : `id, user_id, name, compaction_needed, compaction_in_progress, last_compacted_at, file_size_bytes, file_etag, compression_ratio, row_count, created_at, updated_at`
  - ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: `idx_datasets_user`, `idx_datasets_compaction_needed`, `idx_datasets_updated_at`

- [ ] **processing_metrics** ãƒ†ãƒ¼ãƒ–ãƒ«
  - ã‚«ãƒ©ãƒ : Consumer/Workflow æ®µéšã®å‡¦ç†æ™‚é–“ã€åœ§ç¸®çµ±è¨ˆã€å‡¦ç†çµæœ
  - ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: `idx_metrics_dataset`, `idx_metrics_workflow_instance`, `idx_metrics_created`, `idx_metrics_status`

### ãƒ“ãƒ¥ãƒ¼ç¢ºèª
- [ ] **analytics.metrics_hourly_summary** ãƒ“ãƒ¥ãƒ¼
  - ã‚¹ã‚­ãƒ¼ãƒ: `analytics` (public ã§ã¯ãªã„)
  - ã‚¢ã‚¯ã‚»ã‚¹: Postgres ã‚³ãƒ³ã‚½ãƒ¼ãƒ«çµŒç”±ã®ã¿

- [ ] **analytics.metrics_error_analysis** ãƒ“ãƒ¥ãƒ¼
  - ã‚¹ã‚­ãƒ¼ãƒ: `analytics` (public ã§ã¯ãªã„)
  - ã‚¢ã‚¯ã‚»ã‚¹: Postgres ã‚³ãƒ³ã‚½ãƒ¼ãƒ«çµŒç”±ã®ã¿

### RLS ãƒãƒªã‚·ãƒ¼ç¢ºèª
- [ ] **datasets** ãƒ†ãƒ¼ãƒ–ãƒ« RLS
  - `Users can see their own datasets` (SELECT)
  - `Users can update their own datasets` (UPDATE)

- [ ] **processing_metrics** ãƒ†ãƒ¼ãƒ–ãƒ« RLS
  - `Service role can access all metrics` (ALL)
  - `Users can read metrics for their datasets` (SELECT)

---

## ğŸ§ª ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ†ã‚¹ãƒˆ

### API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãƒ†ã‚¹ãƒˆ
```bash
# 1. ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿè¡Œã®ãƒ†ã‚¹ãƒˆ
curl -X POST https://fusou.pages.dev/api/compaction/trigger-scheduled \
  -H "Content-Type: application/json"

# Expected: { "success": true, "enqueued": 0-N, "datasets": [...] }

# 2. æ‰‹å‹•ã‚³ãƒ³ãƒ‘ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒ†ã‚¹ãƒˆ
curl -X POST https://fusou.pages.dev/api/compaction/sanitize-state \
  -H "Content-Type: application/json" \
  -d '{"datasetId":"<uuid>"}'

# Expected: { "success": true, "datasetId": "<uuid>", "message": "..." }
```

### ãƒ­ã‚°ç¢ºèª
- [ ] Cloudflare Pages: `wrangler tail fusou`
- [ ] Cloudflare Workers: `wrangler tail fusou-workflow`
- [ ] ã‚­ãƒ¥ãƒ¼çŠ¶æ…‹: `wrangler queues list`

---

## âš ï¸ ã‚ˆãã‚ã‚‹è¦‹è½ã¨ã—

1. **dotenvx DOTENV_PRIVATE_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„**
   - Pages ã¨ Workers ä¸¡æ–¹ã§å¿…é ˆ
   - `wrangler secret put` ã§è¨­å®šæ¸ˆã¿ç¢ºèª

2. **PAGES_DOMAIN Secret ãŒãªã„**
   - GitHub Actions ã§ `secrets.PAGES_DOMAIN` ãŒä½¿ç”¨ã•ã‚Œã‚‹
   - Repository Settings ã§è¨­å®šç¢ºèª

3. **ã‚­ãƒ¥ãƒ¼ãŒä½œæˆã•ã‚Œã¦ã„ãªã„**
   - `dev-kc-compaction-queue` ã¨ `dev-kc-compaction-dlq` ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
   - Cloudflare Dashboard â†’ Queues

4. **R2 ãƒã‚±ãƒƒãƒˆã®æ¨©é™ä¸è¶³**
   - Pages/Workers ã‹ã‚‰è©²å½“ãƒã‚±ãƒƒãƒˆã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ç¢ºèª
   - wrangler.toml ã® `bucket_name` ã¨ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ä¸Šã®å®Ÿéš›ã®åå‰ãŒä¸€è‡´

5. **Supabase ã¨ã®æ¥ç¶šãƒ†ã‚¹ãƒˆ**
   - `PUBLIC_SUPABASE_URL` ã¨ `SUPABASE_SECRET_KEY` ãŒæ­£ã—ã„å€¤ã‹ç¢ºèª
   - Supabase ã‚³ãƒ³ã‚½ãƒ¼ãƒ« â†’ SQL Editor ã§ç›´æ¥ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ†ã‚¹ãƒˆ

6. **ãƒ“ãƒ¥ãƒ¼ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è­¦å‘Š**
   - `analytics` ã‚¹ã‚­ãƒ¼ãƒã«ç§»å‹•æ¸ˆã¿ç¢ºèª
   - `public` ã‚¹ã‚­ãƒ¼ãƒã«åŒåãƒ“ãƒ¥ãƒ¼ãŒæ®‹ã£ã¦ã„ãªã„ã‹ç¢ºèª

---

## ğŸ“ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒ 404
- `src/pages/api/[...route].ts` ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
- `src/server/app.ts` ã§ `/compaction` ãƒ«ãƒ¼ãƒˆãŒãƒã‚¦ãƒ³ãƒˆã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª

### ã‚­ãƒ¥ãƒ¼ã«æŠ•å…¥ã•ã‚Œãªã„
- COMPACTION_QUEUE ãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãŒæ­£ã—ã„ã‹ç¢ºèª
- Supabase ã§ `datasets` ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰æ­£ã—ããƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã‚‹ã‹ç¢ºèª

### Workflow ãŒå®Ÿè¡Œã•ã‚Œãªã„
- COMPACTION_WORKFLOW ãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãŒ Pages ã‹ã‚‰è¦‹ãˆã‚‹ã‹ç¢ºèª
- BATTLE_DATA_BUCKET ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ç¢ºèª
- Workflow ã®ã‚¹ã‚­ãƒ¼ãƒãŒæ­£ã—ã„ã‹ç¢ºèª

---

## ğŸ¯ ãƒ‡ãƒ—ãƒ­ã‚¤å®Œäº†æ™‚ã®ãƒã‚§ãƒƒã‚¯

```bash
# ã™ã¹ã¦ã®ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹
wrangler env list

# ã‚­ãƒ¥ãƒ¼ãŒä½œæˆã•ã‚Œã¦ã„ã‚‹
wrangler queues list

# API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒå¿œç­”ã™ã‚‹
curl https://fusou.pages.dev/api/compaction/trigger-scheduled

# DLQ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆç¢ºèª
curl https://fusou.pages.dev/api/compaction/dlq-status | jq

# ãƒ­ã‚°ã« ã‚¨ãƒ©ãƒ¼ãŒãªã„
wrangler tail fusou
wrangler tail fusou-workflow
```

### DLQ ç›£è¦–ã‚¯ã‚¨ãƒªï¼ˆSupabase SQL Editorï¼‰

```sql
-- DLQ å¤±æ•—ãƒ¬ã‚³ãƒ¼ãƒ‰ã®ç¢ºèª
SELECT 
  dataset_id,
  workflow_instance_id,
  status,
  error_message,
  error_step,
  created_at,
  workflow_completed_at
FROM processing_metrics
WHERE status IN ('failure', 'dlq_failure')
ORDER BY created_at DESC
LIMIT 20;

-- DLQ å¤±æ•—çµ±è¨ˆ
SELECT 
  status,
  error_step,
  COUNT(*) as count
FROM processing_metrics
WHERE status IN ('failure', 'dlq_failure')
  AND created_at > now() - interval '7 days'
GROUP BY status, error_step
ORDER BY count DESC;
```

æœ€å¾Œã« GitHub Actions ã§æ‰‹å‹•å®Ÿè¡Œã—ã¦ã¿ã‚‹ â†’ å®Œäº†! ğŸ‰
